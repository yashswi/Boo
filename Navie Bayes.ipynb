{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0f43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve , auc\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484d2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('15_more_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7713d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('15_more_test_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eae50d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_data = df.sample(n=80000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73f27c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbab194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=50000)\n",
    "fill_data['destr_review'] = fill_data['destr_review'].fillna('')\n",
    "test['destr_review'] = test['destr_review'].fillna('')\n",
    "X_vec = vectorizer.fit_transform(fill_data['destr_review'])\n",
    "test_vec = vectorizer.transform(test['destr_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07cc2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fill_data['rating']\n",
    "\n",
    "columns_not_to_drop = 'destr_review'\n",
    "for col in fill_data.columns:\n",
    "    if col not in columns_not_to_drop:\n",
    "        fill_data.drop(columns=col, inplace=True)\n",
    "\n",
    "columns_not_to_drop = 'destr_review'\n",
    "test_copy = test.copy()\n",
    "for col in test.columns:\n",
    "    if col not in columns_not_to_drop:\n",
    "        test.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad05fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "494e04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40cf880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2e466c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "688b594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57eaf0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e48e2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_not_to_drop = 'destr_review'\n",
    "test_copy = test.copy()\n",
    "for col in test.columns:\n",
    "    if col not in columns_not_to_drop:\n",
    "        test.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93cbfe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>destr_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e592483866ae722803c6e40572f9ea4e</td>\n",
       "      <td>21525330</td>\n",
       "      <td>606d3b7ba5cc90e4069b1e225b84deea</td>\n",
       "      <td>Very cute and sweet story about a girl who tra...</td>\n",
       "      <td>Thu Jan 08 14:52:16 -0800 2015</td>\n",
       "      <td>Sun Jan 11 19:53:03 -0800 2015</td>\n",
       "      <td>Sun Jan 11 00:00:00 -0800 2015</td>\n",
       "      <td>Fri Jan 09 00:00:00 -0800 2015</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>cute sweet stori girl travel neverland fall ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52e14841f8745f9761cb85d4ef60ef25</td>\n",
       "      <td>22848621</td>\n",
       "      <td>70388d316638176b827ea060839971ef</td>\n",
       "      <td>No plot regurgitation. \\n This couple are what...</td>\n",
       "      <td>Sat Jul 04 20:37:28 -0700 2015</td>\n",
       "      <td>Fri Feb 03 18:55:30 -0800 2017</td>\n",
       "      <td>Fri Feb 03 00:00:00 -0800 2017</td>\n",
       "      <td>Fri Feb 03 00:00:00 -0800 2017</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>plot regurgit coupl call fantasi fiction not f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202b5764361fb781e18d2e3edeffd599</td>\n",
       "      <td>10852699</td>\n",
       "      <td>840a4fb63336a3fc2213e5016cafbca2</td>\n",
       "      <td>4 stars - Contemporary Romance</td>\n",
       "      <td>Thu Nov 04 10:21:44 -0700 2010</td>\n",
       "      <td>Sat Nov 26 05:48:55 -0800 2011</td>\n",
       "      <td>Fri Nov 25 00:00:00 -0800 2011</td>\n",
       "      <td>Fri Nov 25 00:00:00 -0800 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>star contemporari romanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3519beb3f46f463283ccf9bdbe1622df</td>\n",
       "      <td>11588</td>\n",
       "      <td>6c5865dc54856d1dcb317c3dd42215a8</td>\n",
       "      <td>Another King I've read so many years ago. Back...</td>\n",
       "      <td>Thu Oct 04 03:43:05 -0700 2012</td>\n",
       "      <td>Wed Oct 02 07:17:30 -0700 2013</td>\n",
       "      <td>Thu Jan 01 00:00:00 -0800 1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>anoth king read mani year ago back day read bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4e637c380d40de359012be29091be3b4</td>\n",
       "      <td>15839984</td>\n",
       "      <td>0fdf6c933c0b299ebf5053b8d9a2f950</td>\n",
       "      <td>so good, SO GOOD. it took a while to suck me i...</td>\n",
       "      <td>Wed May 13 17:39:37 -0700 2015</td>\n",
       "      <td>Sun Jan 29 13:26:50 -0800 2017</td>\n",
       "      <td>Mon Aug 17 00:00:00 -0700 2015</td>\n",
       "      <td>Sun Aug 16 00:00:00 -0700 2015</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>good good took suck convinc begin resist long ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  \\\n",
       "0  e592483866ae722803c6e40572f9ea4e  21525330   \n",
       "1  52e14841f8745f9761cb85d4ef60ef25  22848621   \n",
       "2  202b5764361fb781e18d2e3edeffd599  10852699   \n",
       "3  3519beb3f46f463283ccf9bdbe1622df     11588   \n",
       "4  4e637c380d40de359012be29091be3b4  15839984   \n",
       "\n",
       "                          review_id  \\\n",
       "0  606d3b7ba5cc90e4069b1e225b84deea   \n",
       "1  70388d316638176b827ea060839971ef   \n",
       "2  840a4fb63336a3fc2213e5016cafbca2   \n",
       "3  6c5865dc54856d1dcb317c3dd42215a8   \n",
       "4  0fdf6c933c0b299ebf5053b8d9a2f950   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Very cute and sweet story about a girl who tra...   \n",
       "1  No plot regurgitation. \\n This couple are what...   \n",
       "2                     4 stars - Contemporary Romance   \n",
       "3  Another King I've read so many years ago. Back...   \n",
       "4  so good, SO GOOD. it took a while to suck me i...   \n",
       "\n",
       "                       date_added                    date_updated  \\\n",
       "0  Thu Jan 08 14:52:16 -0800 2015  Sun Jan 11 19:53:03 -0800 2015   \n",
       "1  Sat Jul 04 20:37:28 -0700 2015  Fri Feb 03 18:55:30 -0800 2017   \n",
       "2  Thu Nov 04 10:21:44 -0700 2010  Sat Nov 26 05:48:55 -0800 2011   \n",
       "3  Thu Oct 04 03:43:05 -0700 2012  Wed Oct 02 07:17:30 -0700 2013   \n",
       "4  Wed May 13 17:39:37 -0700 2015  Sun Jan 29 13:26:50 -0800 2017   \n",
       "\n",
       "                          read_at                      started_at  n_votes  \\\n",
       "0  Sun Jan 11 00:00:00 -0800 2015  Fri Jan 09 00:00:00 -0800 2015        5   \n",
       "1  Fri Feb 03 00:00:00 -0800 2017  Fri Feb 03 00:00:00 -0800 2017        3   \n",
       "2  Fri Nov 25 00:00:00 -0800 2011  Fri Nov 25 00:00:00 -0800 2011        0   \n",
       "3  Thu Jan 01 00:00:00 -0800 1998                             NaN        3   \n",
       "4  Mon Aug 17 00:00:00 -0700 2015  Sun Aug 16 00:00:00 -0700 2015        1   \n",
       "\n",
       "   n_comments                                       destr_review  \n",
       "0           0  cute sweet stori girl travel neverland fall ca...  \n",
       "1           4  plot regurgit coupl call fantasi fiction not f...  \n",
       "2           0                           star contemporari romanc  \n",
       "3           4  anoth king read mani year ago back day read bo...  \n",
       "4          11  good good took suck convinc begin resist long ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f37d504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "782eddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 5, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c45808c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'review_id':test_copy['review_id'],'rating':predictions}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b04dcba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feab4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bigram\n",
    "random_sample['destr_review'] = random_sample['destr_review'].fillna('')\n",
    "tf_idf_vect=TfidfVectorizer(ngram_range=(1,2))\n",
    "X_bigram =tf_idf_vect.fit_transform(fill_data['destr_review'].values)\n",
    "test['destr_review'] = test['destr_review'].fillna('')\n",
    "test_bigram =tf_idf_vect.transform(test['destr_review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "51002c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc9beeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287ff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7d976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ffc5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "279f7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=40000)\n",
    "fill_data['destr_review'] = fill_data['destr_review'].fillna('')\n",
    "test['destr_review'] = test['destr_review'].fillna('')\n",
    "X_vec = vectorizer.fit_transform(fill_data['destr_review'])\n",
    "test_vec = vectorizer.transform(test['destr_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6f6b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5dc717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 11, 12],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 6, 7],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required at each leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab5ba5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 6, 7],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 11, 12]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0c88a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 12}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52249607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 12}\n",
      "Best Score: 0.43518749999999995\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf59f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
